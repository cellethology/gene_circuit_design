defaults:
  - predictor: ridge_regressor
  - query_strategy: topk
  - initial_selection_strategy: random
  - transforms@feature_transforms: standardize
  - transforms@target_transforms: log_standardize
  - _self_
  - override hydra/launcher: submitit_local

# data paths
dataset_name: ${env:AL_DATASET_NAME}
metadata_path: ${env:AL_METADATA_PATH}
embedding_dir: ${env:AL_EMBEDDING_ROOT}
embedding_model: enformer_pca32
embedding_path: ${embedding_dir}/${embedding_model}.npz

# number of random seeds to run for each active learning experiment
num_seeds_per_job: 50
parallelize_seeds: true

# active learning settings
al_settings:
  batch_size: 8
  starting_batch_size: 8
  max_rounds: 20
  feature_transforms: ${feature_transforms}
  target_transforms: ${target_transforms}
  output_dir: ${hydra:runtime.output_dir}
  query_strategy: ${query_strategy}
  label_key: "Fold Change (Induced/Basal)"
  predictor: ${predictor}
  initial_selection_strategy: ${initial_selection_strategy}
  seed: 0

# hydra settings
hydra:
  sweep:
    subdir: ${dataset_name}/${hydra.job.override_dirname}
  sweeper: # multirun mode sweeps over these parameters
    params:
      initial_selection_strategy: kmeans
      query_strategy: predstdhybrid
      predictor: rf_regressor
      embedding_model: enformer_pca32
  launcher:
    timeout_min: 720
    # everything below is used only for submitting jobs to the cluster
    # partition: wzt_20250411,intel-sc3
    # cpus_per_task: 8
    # mem_per_cpu: 8GB
    # qos: huge
    # submitit_folder: slurm_logs
