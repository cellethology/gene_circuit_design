defaults:
  - predictor: ridge_regressor
  - query_strategy: topk
  - initial_selection_strategy: random
  - transforms@feature_transforms: standardize
  - transforms@target_transforms: log_standardize
  - _self_
  - override hydra/launcher: submitit_local

# data paths
dataset_name: ${env:AL_DATASET_NAME,unknown_dataset}
metadata_path: ${env:AL_METADATA_PATH,""}
embedding_dir: ${env:AL_EMBEDDING_ROOT,"."}
embedding_model: ${env:AL_EMBEDDING_MODEL,""}
embedding_path: ${embedding_dir}/${embedding_model}.npz

# number of random seeds to run for each active learning experiment
num_seeds_per_job: 2
parallelize_seeds: true

# active learning settings
al_settings:
  batch_size: 8
  starting_batch_size: 8
  max_rounds: 20
  feature_transforms: ${feature_transforms}
  target_transforms: ${target_transforms}
  output_dir: ${hydra:runtime.output_dir}
  query_strategy: ${query_strategy}
  label_key: "Fold Change (Induced/Basal)"
  predictor: ${predictor}
  initial_selection_strategy: ${initial_selection_strategy}
  seed: 0

# hydra settings
hydra:
  sweep:
    subdir: ${dataset_name}/${hydra.job.override_dirname}
  sweeper: # multirun mode sweeps over these parameters
    params:
      initial_selection_strategy: random
      query_strategy: topk
      predictor: ridge_regressor
      embedding_model: enformer_pca32, evo_1p5_pca32
  # launcher: # only used for submitting jobs to the cluster
  #   timeout_min: 240
  #   partition: wzt_20250411,intel-sc3
  #   cpus_per_task: 8
  #   mem_per_cpu: 8GB
  #   qos: huge
  #   submitit_folder: logs_experiments
